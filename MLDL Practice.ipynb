{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca542e59-614d-4f2f-8ae6-f8b149851292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# ì—¬ëŸ¬ ì—´ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ ì „ì²˜ë¦¬ê¸°ë¥¼ ì ìš©í•  ìˆ˜ ìˆê²Œ í•¨ \n",
    "# ìˆ«ìí˜• ì—´ì—ëŠ” í‘œì¤€í™” _ StandardScaler\n",
    "# ë²”ì£¼í˜• ì—´ì—ëŠ” _ OneHotEncoder \n",
    "# ì´ëŸ° ê±¸ í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ \n",
    "from sklearn.pipeline import Pipeline\n",
    "# ì—¬ëŸ¬ ë‹¨ê³„ì˜ ë¨¸ì‹ ëŸ¬ë‹ ì‘ì—…ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ì„œ ê¹”ë” ì²˜ë¦¬í•˜ê²Œ í•´ì£¼ëŠ” ë„êµ¬ \n",
    "# pipe = Pipeline([\n",
    "#     ('imputer', SimpleImputer(strategy='mean')),      # ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
    "#     ('scaler', StandardScaler()),                     # ì •ê·œí™”\n",
    "#     ('classifier', LogisticRegression())              # ëª¨ë¸ í•™ìŠµ\n",
    "# ])\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "# ê²°ì¸¡ê°’ ì²˜ë¦¬ ìœ„í•œ ë„êµ¬ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œ \n",
    "# ë°ì´í„°ì…‹ì— **NaN(ê²°ì¸¡ê°’)**ì´ ìˆì„ ë•Œ, ê·¸ ìë¦¬ë¥¼ í‰ê· , ì¤‘ì•™ê°’, ìµœë¹ˆê°’ ë“±ìœ¼ë¡œ ì±„ì›Œì£¼ëŠ” ì—­í• \n",
    "# - strategy='mean': í‰ê· ê°’ìœ¼ë¡œ ì±„ì›€\n",
    "# - strategy='median': ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ì›€\n",
    "# - strategy='most_frequent': ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ê°’ìœ¼ë¡œ ì±„ì›€\n",
    "# - strategy='constant': ì‚¬ìš©ìê°€ ì§€ì •í•œ ê°’ìœ¼ë¡œ ì±„ì›€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a909fb85-0e93-4f3a-abe6-831c8245d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "# rc: runtime configuration\n",
    "rc(\"font\", family='Malgun Gothic')\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c34a323-df2c-4a61-a28d-365ffa0ec6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "submission = pd.read_csv(\"./sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994eac5e-0f2d-4a5a-8d3c-049d33cc607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>7</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>25</td>\n",
       "      <td>aug</td>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>514</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>18</td>\n",
       "      <td>jun</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>602</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>14</td>\n",
       "      <td>may</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>34</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>28</td>\n",
       "      <td>may</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>889</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>3</td>\n",
       "      <td>feb</td>\n",
       "      <td>902</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age          job  marital  education default  balance housing loan  \\\n",
       "0   0   42   technician  married  secondary      no        7      no   no   \n",
       "1   1   38  blue-collar  married  secondary      no      514      no   no   \n",
       "2   2   36  blue-collar  married  secondary      no      602     yes   no   \n",
       "3   3   27      student   single  secondary      no       34     yes   no   \n",
       "4   4   26   technician  married  secondary      no      889     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0  cellular   25   aug       117         3     -1         0  unknown  0  \n",
       "1   unknown   18   jun       185         1     -1         0  unknown  0  \n",
       "2   unknown   14   may       111         2     -1         0  unknown  0  \n",
       "3   unknown   28   may        10         2     -1         0  unknown  0  \n",
       "4  cellular    3   feb       902         1     -1         0  unknown  1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7cc42bf-34b9-46d6-b041-2633b95e41e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750000</td>\n",
       "      <td>32</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1397</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>21</td>\n",
       "      <td>may</td>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>750001</td>\n",
       "      <td>44</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>23</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>3</td>\n",
       "      <td>apr</td>\n",
       "      <td>586</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>750002</td>\n",
       "      <td>36</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>46</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>13</td>\n",
       "      <td>may</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>750003</td>\n",
       "      <td>58</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-1380</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>29</td>\n",
       "      <td>may</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750004</td>\n",
       "      <td>28</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1950</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>22</td>\n",
       "      <td>jul</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  age            job  marital  education default  balance housing  \\\n",
       "0  750000   32    blue-collar  married  secondary      no     1397     yes   \n",
       "1  750001   44     management  married   tertiary      no       23     yes   \n",
       "2  750002   36  self-employed  married    primary      no       46     yes   \n",
       "3  750003   58    blue-collar  married  secondary      no    -1380     yes   \n",
       "4  750004   28     technician   single  secondary      no     1950     yes   \n",
       "\n",
       "  loan   contact  day month  duration  campaign  pdays  previous poutcome  \n",
       "0   no   unknown   21   may       224         1     -1         0  unknown  \n",
       "1   no  cellular    3   apr       586         2     -1         0  unknown  \n",
       "2  yes  cellular   13   may       111         2     -1         0  unknown  \n",
       "3  yes   unknown   29   may       125         1     -1         0  unknown  \n",
       "4   no  cellular   22   jul       181         1     -1         0  unknown  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d788179-c437-4de5-a169-94339462bf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_in_train = set(train.columns) - set(test.columns)\n",
    "unique_in_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e088ca4-959c-4353-8c8c-0fb3e05e8f79",
   "metadata": {},
   "source": [
    "# ì…ë ¥ ë³€ìˆ˜(X), íƒ€ê²Ÿ(y) ë¶„ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bcdbb93-f3dd-45e7-ae20-e7653603fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=[\"y\"])\n",
    "y = train[\"y\"]\n",
    "\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104b64c-02ca-4440-81c8-1ad38e59421c",
   "metadata": {},
   "source": [
    "# ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a5e4b9-a083-4474-8c2d-c3e0b06ff9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hto encoding / scailingì€ train + test í•©ì³ì„œ fit í•˜ê³  ë‹¤ì‹œ ë‚˜ëˆ ì£¼ëŠ” ê²Œ ì•ˆì „ \n",
    "full = pd.concat([X, X_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a33a019-caf5-4669-bb1b-3cab05568d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'job', 'marital', 'education', 'default', 'balance',\n",
       "       'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign',\n",
       "       'pdays', 'previous', 'poutcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9db16fec-3b75-41bf-b2cc-d25c02f6d09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            int64\n",
       "age           int64\n",
       "job          object\n",
       "marital      object\n",
       "education    object\n",
       "default      object\n",
       "balance       int64\n",
       "housing      object\n",
       "loan         object\n",
       "contact      object\n",
       "day           int64\n",
       "month        object\n",
       "duration      int64\n",
       "campaign      int64\n",
       "pdays         int64\n",
       "previous      int64\n",
       "poutcome     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bf27ff6-8e8b-4a9b-a45f-1144417c1b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750000 entries, 0 to 749999\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   id         750000 non-null  int64 \n",
      " 1   age        750000 non-null  int64 \n",
      " 2   job        750000 non-null  object\n",
      " 3   marital    750000 non-null  object\n",
      " 4   education  750000 non-null  object\n",
      " 5   default    750000 non-null  object\n",
      " 6   balance    750000 non-null  int64 \n",
      " 7   housing    750000 non-null  object\n",
      " 8   loan       750000 non-null  object\n",
      " 9   contact    750000 non-null  object\n",
      " 10  day        750000 non-null  int64 \n",
      " 11  month      750000 non-null  object\n",
      " 12  duration   750000 non-null  int64 \n",
      " 13  campaign   750000 non-null  int64 \n",
      " 14  pdays      750000 non-null  int64 \n",
      " 15  previous   750000 non-null  int64 \n",
      " 16  poutcome   750000 non-null  object\n",
      "dtypes: int64(8), object(9)\n",
      "memory usage: 97.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d72b7b8-806d-41a7-a2c8-aca13432e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = full.select_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a367838b-4de8-4b95-8ca6-d846c12d9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = full.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "# OneHotEncoding\n",
    "full = pd.get_dummies(full, columns=cat_cols, drop_first=True)\n",
    "# Scailing \n",
    "# scaler = StandardScaler()\n",
    "# full[num_cols] = scaler.fit_transform(full[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d25c5596-e738-402e-9b57-b7f62f340257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'poutcome']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e3a96c-e6b2-4ad8-8502-0e22061f3442",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full.iloc[:len(X), :]\n",
    "X_test = full.iloc[len(X):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3635e585-50bf-42a8-afb0-52646767226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "# stratify=y: ë°ì´í„° ë‚˜ëˆŒ ë•Œ ë¹„ìœ¨ ìœ ì§€í•˜ê² ë‹¤ëŠ” ëœ» _ ê° í´ë˜ìŠ¤(0,1)ì˜ ë¹„ìœ¨ì´ ì „ì²´ ë°ì´í„°ì˜ yì™€ ê°™ê²Œ ë‚˜ëˆ„ì–´ì§ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6973cd8a-9c3c-426e-bf71-79b1fb4cf036",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.replace(\"unknown\", np.nan)\n",
    "X_valu = X_val.replace(\"unknown\", np.nan)\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "\n",
    "num_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                    (\"sc\", StandardScaler())])\n",
    "# pipeline ì•ˆì— ì—¬ëŸ¬ ë‹¨ê³„ê°€ ìˆì„ ë•Œ, ê°ê°ì„ ì‹ë³„í•˜ëŠ” ìš©ë„ë¡œ imp, scë¥¼ ì”€ \n",
    "# ì˜ˆë¥¼ ë“¤ì–´ GridSearchCVë¥¼ ì‚¬ìš©í•  ë•Œ, ê° ë‹¨ê³„ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ë ¤ë©´ ì´ë¦„ì´ ìˆì–´ì•¼ í•¨ \n",
    "# param_grid = {\n",
    "#     'imp__strategy': ['mean', 'median'],\n",
    "#     'sc__with_mean': [True, False]\n",
    "# }\n",
    "cat_pipe = Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33380e2d-fc0d-4d79-8d5c-ce587188a9b6",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0acca7b-66d6-411e-8b19-73be1d2e06ba",
   "metadata": {},
   "source": [
    "## Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aba56b0-8c54-48bc-939f-b0649f4c5001",
   "metadata": {},
   "source": [
    "## kernel\n",
    "- ë³µì¡í•œ íŒ¨í„´ì„ ì¡ìœ¼ë ¤ë©´ ì…ë ¥ì„ ê³ ì°¨ì› íŠ¹ì§•ê³µê°„ìœ¼ë¡œ ë°”ê¿”ì„œ ì„ í˜•ìœ¼ë¡œ ìë¥´ë©´ ì‰½ë‹¤(â€œíŠ¹ì§• ë§µâ€ Ï†(x)).\n",
    "- ê·¸ëŸ°ë° Ï†(x)ê°€ ì—„ì²­ ê³ ì°¨ì›ì´ë©´ ì§ì ‘ ê³„ì‚°ì´ ë„ˆë¬´ ë¹„ì‹¸ë‹¤.\n",
    "- ì»¤ë„ íŠ¸ë¦­: ë‘ ì ì˜ ê³ ì°¨ì› ë‚´ì  âŸ¨Ï†(x), Ï†(z)âŸ©ì„ ì»¤ë„ í•¨ìˆ˜ K(x, z)ë¡œ ë°”ë¡œ ê³„ì‚°í•œë‹¤.\n",
    "- ì¦‰, ë§µí•‘ì€ â€œì•”ì‹œì ìœ¼ë¡œâ€ í•˜ê³ , ìš°ë¦¬ëŠ” Kë§Œ ê³„ì‚°í•˜ë©´ ëœë‹¤.\n",
    "- SVM/ì»¤ë„ë¦¿ë“¤ì´ ê²°êµ­ â€œì»¤ë„ í–‰ë ¬(Gram matrix)â€ K_ij = K(x_i, x_j)ë§Œìœ¼ë¡œ í•™ìŠµí•œë‹¤.\n",
    "### RBF(ê°€ìš°ì‹œì•ˆ) ì»¤ë„\n",
    "ì •ì˜: K(x,z)=exp(âˆ’Î³âˆ¥xâˆ’zâˆ¥2)\\\n",
    "ë˜ëŠ” Î³=1/2Ïƒ^2ë¡œ ì“°ê¸°ë„ í•¨.\\\n",
    "í•´ì„: ë‘ ìƒ˜í”Œì´ ê°€ê¹Œìš°ë©´(ìœ í´ë¦¬ë“œ ê±°ë¦¬ ì‘ìœ¼ë©´) ìœ ì‚¬ë„â‰ˆ1, ë©€ë©´ 0ì— ìˆ˜ë ´.\\\n",
    "ì¦‰, **â€œê°€ê¹Œìš´ ì´ì›ƒì€ ë¹„ìŠ·í•˜ë‹¤â€**ëŠ” ê°€ì •ìœ¼ë¡œ ë§¤ëˆí•œ ê³¡ë©´ ê²°ì •ê²½ê³„ë¥¼ ë§Œë“ ë‹¤.\\\n",
    "íŠ¹ì§•: ë¬´í•œì°¨ì› íŠ¹ì§•ê³µê°„ì— í•´ë‹¹(ì´ë¡ ì ìœ¼ë¡œ ë§¤ìš° í‘œí˜„ë ¥ í’ë¶€). ê·¸ë˜ì„œ ë²”ìš©ìœ¼ë¡œ ì˜ ë¨¹íŒë‹¤.\n",
    "\n",
    "**í•µì‹¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°**\n",
    "- Î³ (gamma): â€œê°€ê¹Œì›€â€ì˜ ê¸°ì¤€(ìŠ¤ì¼€ì¼).\n",
    "    - ì‘ì€ Î³ â†’ ë„“ì€ ì¢…(bandwidth í¼) â†’ ë¶€ë“œëŸ¬ìš´ ê²½ê³„(ë°”ì´ì–´ìŠ¤â†‘, ë¶„ì‚°â†“).\\\n",
    "    - í° Î³ â†’ ì¢ì€ ì¢…(bandwidth ì‘ìŒ) â†’ ìš”ì²  ë§ì€ ê²½ê³„(ë°”ì´ì–´ìŠ¤â†“, ë¶„ì‚°â†‘, ê³¼ì í•© ìœ„í—˜).\\\n",
    "    - ê´€ê³„: Ïƒ=1/2Î³\\\n",
    "    - scikit-learn ê¸°ë³¸ê°’ gamma=\"scale\"ì€ \\gamma = \\frac{1}{\\text{n_features} \\cdot \\text{Var}(X)}.\n",
    "- C(ê·œì œ ê°•ë„): ë§ˆì§„ ìµœëŒ€í™” vs ì˜¤ë¶„ë¥˜ íŒ¨ë„í‹°ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„.\n",
    "    - í° C: ì˜¤ë¶„ë¥˜ë¥¼ ëœ í—ˆìš© â†’ ê²½ê³„ê°€ ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŒ(ê³¼ì í•© ìœ„í—˜).\n",
    "    - ì‘ì€ C: ì˜¤ë¶„ë¥˜ ì¢€ í—ˆìš© â†’ ê²½ê³„ê°€ ë¶€ë“œëŸ¬ì›€(ê³¼ì†Œì í•© ìœ„í—˜).\n",
    "- Cì™€ Î³ì˜ ìƒí˜¸ì‘ìš©:\n",
    "    - ë‘˜ ë‹¤ ë³µì¡ë„ë¥¼ í‚¤ìš°ëŠ” ë°©í–¥ìœ¼ë¡œ ì‘ë™ ê°€ëŠ¥ â†’ **(Câ†‘, Î³â†‘)**ëŠ” ê°€ì¥ ê³µê²©ì (ê³¼ì í•© ì£¼ì˜).\n",
    "    - ë³´í†µ ë¡œê·¸ìŠ¤ì¼€ì¼ ê·¸ë¦¬ë“œ ì„œì¹˜ë¡œ í•¨ê»˜ íŠœë‹í•œë‹¤.\n",
    "\n",
    "**ê¼­ ì§€ì¼œì•¼ í•˜ëŠ” ì „ì²˜ë¦¬**\n",
    "- ìŠ¤ì¼€ì¼ë§ í•„ìˆ˜(í‘œì¤€í™”/MinMax). ê±°ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ ë‹¨ìœ„Â·ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥´ë©´ ì™œê³¡ë¨.\n",
    "- ì›-í•« ê³ ì°¨ì› í¬ì†Œë²¡í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ê±°ë¦¬ì˜ ì˜ë¯¸ê°€ ì•½í•´ì§ˆ ìˆ˜ ìˆìŒ â†’ íŠ¸ë¦¬ê³„ì—´ì´ë‚˜ ì„ í˜• ëª¨ë¸ ê²€í† .\n",
    "\n",
    "**ì–¸ì œ RBFê°€ ì¢‹ì€ê°€?**\n",
    "- ì¤‘/ì†Œê·œëª¨ í‘œë³¸ì—ì„œ ë¹„ì„ í˜• ê²½ê³„ê°€ í•„ìš”í•œ ë¶„ë¥˜/íšŒê·€.\n",
    "- íŠ¹ì§• ìˆ˜ëŠ” ì ë‹¹í•˜ê³ (ìˆ˜~ìˆ˜ì‹­), ìŠ¤ì¼€ì¼ë§ì´ ì˜ ë˜ì–´ ìˆì„ ë•Œ.\n",
    "\n",
    "**í•œê³„ì™€ ëŒ€ì•ˆ**\n",
    "- ì‹œê°„/ë©”ëª¨ë¦¬ ë³µì¡ë„ê°€ ìƒ˜í”Œ ìˆ˜ì— ë¹„ì„ í˜•ìœ¼ë¡œ ì»¤ì§„ë‹¤(ì»¤ë„ í–‰ë ¬ O(nÂ²)).\\\n",
    "ë°ì´í„°ê°€ ì•„ì£¼ í¬ë©´ Linear SVM, XGBoost/LightGBM, í˜¹ì€ ê·¼ì‚¬ ì»¤ë„(Nystrom, RFF) ê³ ë ¤.\n",
    "- í™•ë¥  ì¶œë ¥ì´ í•„ìš”í•˜ë©´ probability=Trueë¡œ Platt scaling(ì¶”ê°€ ë¹„ìš©)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c08ee-e322-4909-9511-19d49bc48c53",
   "metadata": {},
   "source": [
    "# ğŸŒ² Step-by-Step: ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ì‘ë™ ë°©ì‹\n",
    "\n",
    "1. ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œë§ (Bagging)\n",
    "- ì „ì²´ ì´ë©”ì¼ ë°ì´í„°ì—ì„œ ì¤‘ë³µ í—ˆìš©í•˜ë©° ëœë¤í•˜ê²Œ ìƒ˜í”Œì„ ë½‘ì•„ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ ë°ì´í„°ì…‹ì„ ë§Œë“ ë‹¤.\n",
    "- ì˜ˆë¥¼ ë“¤ì–´, 400ê°œì˜ íŠ¸ë¦¬ë¥¼ ë§Œë“¤ê¸°ë¡œ í–ˆìœ¼ë‹ˆ, 400ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ìƒ˜í”Œë§ëœ ë°ì´í„°ì…‹ì´ ìƒê¸´ë‹¤.\n",
    "  \n",
    "2. ëœë¤ í”¼ì²˜ ì„ íƒ\n",
    "- ê° íŠ¸ë¦¬ëŠ” í•™ìŠµí•  ë•Œ ì „ì²´ í”¼ì²˜ ì¤‘ ì¼ë¶€ë§Œ ëœë¤í•˜ê²Œ ì„ íƒí•´ì„œ ì‚¬ìš©í•œë‹¤.\n",
    "- ì˜ˆë¥¼ ë“¤ì–´, ì–´ë–¤ íŠ¸ë¦¬ëŠ” \"ë¬´ë£Œ\"ì™€ \"ì²¨ë¶€íŒŒì¼\"ë§Œ ë³´ê³  íŒë‹¨í•˜ê³ , ë‹¤ë¥¸ íŠ¸ë¦¬ëŠ” \"ë°œì‹ ì\"ì™€ \"ì´ë©”ì¼ ê¸¸ì´\"ë§Œ ë³¸ë‹¤.\n",
    "\n",
    "3. ê°œë³„ ê²°ì • íŠ¸ë¦¬ í•™ìŠµ\n",
    "- ê° íŠ¸ë¦¬ëŠ” ìì‹ ë§Œì˜ ë°ì´í„°ì™€ í”¼ì²˜ë¥¼ ê°€ì§€ê³  ìŠ¤íŒ¸ì¸ì§€ ì•„ë‹Œì§€ë¥¼ íŒë‹¨í•˜ëŠ” ê·œì¹™ì„ ë§Œë“ ë‹¤.\n",
    "- ì–´ë–¤ íŠ¸ë¦¬ëŠ” \"ë¬´ë£Œ\"ë¼ëŠ” ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ìŠ¤íŒ¸ì´ë¼ê³  í•˜ê³ , ë‹¤ë¥¸ íŠ¸ë¦¬ëŠ” \"ì²¨ë¶€íŒŒì¼\"ì´ ìˆìœ¼ë©´ ìŠ¤íŒ¸ì´ë¼ê³  í•  ìˆ˜ë„ ìˆì–´.\n",
    "  \n",
    "4. ì˜ˆì¸¡ ì‹œ íˆ¬í‘œ\n",
    "- ìƒˆë¡œìš´ ì´ë©”ì¼ì´ ë“¤ì–´ì˜¤ë©´, 400ê°œì˜ íŠ¸ë¦¬ ê°ê°ì´ ìì‹ ì˜ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•œë‹¤.\n",
    "- ì˜ˆ: 400ê°œ ì¤‘ 320ê°œê°€ \"ìŠ¤íŒ¸\"ì´ë¼ê³  í•˜ë©´ â†’ ìµœì¢… ì˜ˆì¸¡ì€ \"ìŠ¤íŒ¸\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c66fc-ed98-4060-b78d-ca697e4cc12f",
   "metadata": {},
   "source": [
    "# ğŸŒ± GBDTì˜ ì‘ë™ ì›ë¦¬: â€œì”ì°¨ë¥¼ ì¤„ì—¬ê°€ë©° íŠ¸ë¦¬ë¥¼ ìŒ“ëŠ”ë‹¤â€\n",
    "\n",
    "1. ì²« ë²ˆì§¸ íŠ¸ë¦¬\n",
    "- ì²˜ìŒì—” ì•„ì£¼ ë‹¨ìˆœí•œ íŠ¸ë¦¬ë¥¼ í•˜ë‚˜ ë§Œë“ ë‹¤.\n",
    "- ì´ íŠ¸ë¦¬ëŠ” ëŒ€ì¶© í‰ê· ê°’ì´ë‚˜ ê°„ë‹¨í•œ ê·œì¹™ìœ¼ë¡œ ì˜ˆì¸¡ì„ í•œë‹¤.\n",
    "- ë‹¹ì—°íˆ ì˜¤ì°¨(ì”ì°¨)ê°€ ë§ì´ ìƒê¸°ê² ì§€?\n",
    "  \n",
    "2. ë‘ ë²ˆì§¸ íŠ¸ë¦¬\n",
    "- ì´ì œ ì²« ë²ˆì§¸ íŠ¸ë¦¬ê°€ í‹€ë¦° ë¶€ë¶„(ì”ì°¨)ì„ í•™ìŠµí•´ì„œ ë³´ì •í•˜ëŠ” íŠ¸ë¦¬ë¥¼ ë§Œë“ ë‹¤.\n",
    "- ì˜ˆë¥¼ ë“¤ì–´, ì²« ë²ˆì§¸ íŠ¸ë¦¬ê°€ 5ì–µì´ë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ë° ì‹¤ì œëŠ” 6ì–µì´ë©´, ë‘ ë²ˆì§¸ íŠ¸ë¦¬ëŠ” ê·¸ 1ì–µ ì°¨ì´ë¥¼ ì¤„ì´ë ¤ê³  ë…¸ë ¥í•¨.\n",
    "\n",
    "3. ì„¸ ë²ˆì§¸, ë„¤ ë²ˆì§¸...\n",
    "- ì´ëŸ° ì‹ìœ¼ë¡œ ì”ì°¨ë¥¼ ì¤„ì´ëŠ” íŠ¸ë¦¬ë“¤ì„ ê³„ì† ìŒ“ì•„ê°€ë©´ì„œ, ì ì  ë” ì •êµí•œ ì˜ˆì¸¡ì„ í•˜ê²Œ ë¼.\n",
    "- ê° íŠ¸ë¦¬ëŠ” ì•½í•œ ëª¨ë¸ì´ì§€ë§Œ, ëª¨ë‘ í•©ì¹˜ë©´ ê°•ë ¥í•œ ëª¨ë¸ì´ ë˜ëŠ” ê±°ì•¼.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d73d14-13d3-45fb-a72c-df3cad4ed1f8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ XGBClassifierë€?\n",
    "\n",
    "`XGBClassifier`ëŠ” **XGBoost (Extreme Gradient Boosting)** ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë¶„ë¥˜ê¸° ë²„ì „ì´ì•¼. ì´ë¦„ë¶€í„° â€œìµìŠ¤íŠ¸ë¦¼â€ì´ ë¶™ì—ˆì§€? ê·¸ë§Œí¼ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„ ê·¹í•œê¹Œì§€ ëŒì–´ì˜¬ë¦° GBDTì˜ ì—…ê·¸ë ˆì´ë“œ ë²„ì „ì´ë¼ê³  ë³´ë©´ ë¼.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ GBDT vs XGBoost: ë­ê°€ ë‹¬ë¼ì¡Œì„ê¹Œ?\n",
    "\n",
    "| í•­ëª© | GradientBoostingClassifier | XGBClassifier |\n",
    "|------|-----------------------------|---------------|\n",
    "| **í•™ìŠµ ë°©ì‹** | ì”ì°¨ ê¸°ë°˜ ë¶€ìŠ¤íŒ… | ì”ì°¨ + ì •ê·œí™” + ë” ë˜‘ë˜‘í•œ íŠ¸ë¦¬ |\n",
    "| **ì†ë„** | ëŠë¦¼ (ìˆœì°¨ì  í•™ìŠµ) | ë¹ ë¦„ (ë³‘ë ¬ ì²˜ë¦¬, ìºì‹œ ìµœì í™”) |\n",
    "| **ê³¼ì í•© ë°©ì§€** | learning_rateë¡œ ì¡°ì ˆ | ì •ê·œí™”(L1/L2), early stopping ë“± ë‹¤ì–‘í•¨ |\n",
    "| **ê²°ì¸¡ì¹˜ ì²˜ë¦¬** | ì§ì ‘ ì²˜ë¦¬ í•„ìš” | ìë™ ì²˜ë¦¬ ê°€ëŠ¥ |\n",
    "| **ì„±ëŠ¥** | ì¢‹ìŒ | ë” ì¢‹ìŒ (íŠ¹íˆ ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ) |\n",
    "| **ì‚¬ìš© í¸ì˜ì„±** | ë¹„êµì  ë‹¨ìˆœ | íŒŒë¼ë¯¸í„° ë§ì§€ë§Œ íŠœë‹ ì—¬ì§€ í¼ |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  XGBClassifierì˜ í•µì‹¬ ë°œì „ í¬ì¸íŠ¸\n",
    "\n",
    "### 1. **ì •ê·œí™”(Regularization)**\n",
    "- GBDTëŠ” íŠ¸ë¦¬ë¥¼ ê³„ì† ìŒ“ë‹¤ ë³´ë©´ ê³¼ì í•© ìœ„í—˜ì´ ì»¤.\n",
    "- XGBoostëŠ” **L1, L2 ì •ê·œí™”**ë¥¼ í†µí•´ ëª¨ë¸ ë³µì¡ë„ë¥¼ ì œì–´í•´ì„œ ê³¼ì í•©ì„ ë°©ì§€í•´.\n",
    "\n",
    "### 2. **ë³‘ë ¬ ì²˜ë¦¬**\n",
    "- GBDTëŠ” íŠ¸ë¦¬ë¥¼ í•˜ë‚˜ì”© ìˆœì°¨ì ìœ¼ë¡œ í•™ìŠµí•˜ì§€ë§Œ,\n",
    "- XGBoostëŠ” **ë…¸ë“œ ë¶„í• ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬**í•´ì„œ í›¨ì”¬ ë¹ ë¥´ê²Œ í•™ìŠµí•¨.\n",
    "\n",
    "### 3. **ê²°ì¸¡ì¹˜ ìë™ ì²˜ë¦¬**\n",
    "- XGBoostëŠ” ê²°ì¸¡ê°’ì´ ìˆì–´ë„ ì•Œì•„ì„œ ì²˜ë¦¬í•´ì¤˜ì„œ ì „ì²˜ë¦¬ ë¶€ë‹´ì´ ì¤„ì–´ë“¤ì–´.\n",
    "\n",
    "### 4. **Early Stopping**\n",
    "- ê²€ì¦ ì„±ëŠ¥ì´ ë” ì´ìƒ ì¢‹ì•„ì§€ì§€ ì•Šìœ¼ë©´ í•™ìŠµì„ ë©ˆì¶”ëŠ” ê¸°ëŠ¥.\n",
    "- ë¶ˆí•„ìš”í•œ íŠ¸ë¦¬ ìƒì„±ì„ ë§‰ê³ , ê³¼ì í•©ë„ ì¤„ì—¬ì¤Œ.\n",
    "\n",
    "### 5. **íŠ¸ë¦¬ êµ¬ì¡° ìµœì í™”**\n",
    "- ê¸°ì¡´ GBDTëŠ” ê¹Šì´ ìš°ì„  ë°©ì‹ìœ¼ë¡œ íŠ¸ë¦¬ë¥¼ ë§Œë“¤ì§€ë§Œ,\n",
    "- XGBoostëŠ” **ìµœì  ë¶„í• ì„ ë” ë˜‘ë˜‘í•˜ê²Œ ê³„ì‚°**í•´ì„œ ì„±ëŠ¥ì´ ë” ì¢‹ì•„.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¡ ì˜ˆì‹œë¡œ ë‹¤ì‹œ ëŒì•„ê°€ë³´ì: ì§‘ê°’ ì˜ˆì¸¡\n",
    "\n",
    "- GBDTëŠ” ì§‘ê°’ì„ ì˜ˆì¸¡í•  ë•Œ, ë°© ê°œìˆ˜ë‚˜ í‰ìˆ˜ ê°™ì€ í”¼ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì”ì°¨ë¥¼ ì¤„ì—¬ê°€ë©° íŠ¸ë¦¬ë¥¼ ìŒ“ì•„.\n",
    "- XGBoostëŠ” ê°™ì€ ì‘ì—…ì„ í•˜ë˜, **ë” ë¹ ë¥´ê²Œ**, **ë” ì •êµí•˜ê²Œ**, ê·¸ë¦¬ê³  **ê³¼ì í•©ì„ ë§‰ìœ¼ë©´ì„œ** ì˜ˆì¸¡í•´.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ í•œ ì¤„ ìš”ì•½\n",
    "\n",
    "> XGBClassifierëŠ” GBDTë¥¼ â€œì†ë„, ì„±ëŠ¥, ì•ˆì •ì„±â€ ë©´ì—ì„œ ê·¹í•œê¹Œì§€ ëŒì–´ì˜¬ë¦° ì§„í™”í˜• ëª¨ë¸ì´ì•¼. ì‹¤ë¬´ì—ì„œ ë§ì´ ì“°ì´ëŠ” ì´ìœ ê°€ ë‹¤ ìˆì–´!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4afb5a-2db6-4d1d-aa86-a46f55994363",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸŒ± LGBMClassifierë€?\n",
    "\n",
    "**LightGBM**ì€ Microsoftì—ì„œ ë§Œë“  GBDT ê¸°ë°˜ì˜ ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ì•¼.  \n",
    "í•µì‹¬ ëª©í‘œëŠ” **ì†ë„ì™€ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•˜ë©´ì„œë„ ì„±ëŠ¥ì€ ìœ ì§€í•˜ê±°ë‚˜ ë” ì¢‹ê²Œ** ë§Œë“œëŠ” ê²ƒ!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  GBDT â†’ XGBoost â†’ LightGBM: ì§„í™” íë¦„\n",
    "\n",
    "| ëª¨ë¸ | íŠ¹ì§• |\n",
    "|------|------|\n",
    "| GBDT | ê¸°ë³¸ ë¶€ìŠ¤íŒ…. ëŠë¦¬ê³  ê³¼ì í•© ìœ„í—˜ ìˆìŒ |\n",
    "| XGBoost | ë¹ ë¥´ê³  ì •êµí•¨. ì •ê·œí™”, ë³‘ë ¬ ì²˜ë¦¬ ë„ì… |\n",
    "| **LightGBM** | í›¨ì”¬ ë¹ ë¦„. ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ìµœì í™”. í¬ì†Œ/ê³ ì°¨ì› ë°ì´í„°ë„ ì˜ ì²˜ë¦¬ |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” LightGBMì˜ í•µì‹¬ ê¸°ìˆ \n",
    "\n",
    "### 1. **Leaf-wise ì„±ì¥ ë°©ì‹**\n",
    "- ê¸°ì¡´ GBDTë‚˜ XGBoostëŠ” íŠ¸ë¦¬ë¥¼ **depth-wise**ë¡œ í‚¤ì›Œ (ê· í˜• ìˆê²Œ).\n",
    "- LightGBMì€ **leaf-wise**ë¡œ í‚¤ì›Œì„œ **ì˜¤ì°¨ë¥¼ ê°€ì¥ ë§ì´ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œë§Œ ì„±ì¥**í•¨.\n",
    "- ê²°ê³¼ì ìœ¼ë¡œ **ë” ê¹Šê³  ì •êµí•œ íŠ¸ë¦¬**ê°€ ë§Œë“¤ì–´ì ¸ì„œ ì„±ëŠ¥ì´ ì¢‹ì•„ì§.\n",
    "\n",
    "### 2. **Histogram ê¸°ë°˜ í•™ìŠµ**\n",
    "- ì—°ì†í˜• í”¼ì²˜ë¥¼ **êµ¬ê°„ë³„ë¡œ ë¬¶ì–´ì„œ(histogram)** ì²˜ë¦¬í•¨.\n",
    "- ë•ë¶„ì— **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í™• ì¤„ê³ **, **ì†ë„ë„ ë¹¨ë¼ì§**.\n",
    "\n",
    "### 3. **í¬ì†Œ ë°ì´í„° ì²˜ë¦¬ì— ê°•í•¨**\n",
    "- í…ìŠ¤íŠ¸ ë²¡í„°ì²˜ëŸ¼ **0ì´ ë§ì€ í¬ì†Œí•œ ë°ì´í„°**ë„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•¨.\n",
    "- XGBoostë³´ë‹¤ ì´ ë¶€ë¶„ì—ì„œ ë” ìœ ë¦¬í•¨.\n",
    "\n",
    "### 4. **GPU ì§€ì›**\n",
    "- GPUë¥¼ í™œìš©í•´ì„œ ëŒ€ê·œëª¨ ë°ì´í„°ë„ ë¹ ë¥´ê²Œ í•™ìŠµ ê°€ëŠ¥!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¡ ì˜ˆì‹œ: ì•„íŒŒíŠ¸ ê°€ê²© ì˜ˆì¸¡\n",
    "\n",
    "- GBDTëŠ” ì”ì°¨ë¥¼ ì¤„ì´ëŠ” íŠ¸ë¦¬ë¥¼ ìŒ“ì•„ê°€ë©° ì˜ˆì¸¡\n",
    "- XGBoostëŠ” ë³‘ë ¬ ì²˜ë¦¬ì™€ ì •ê·œí™”ë¡œ ë” ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ ì˜ˆì¸¡\n",
    "- **LightGBMì€**:\n",
    "  - ë” ë¹ ë¥´ê²Œ\n",
    "  - ë” ì ì€ ë©”ëª¨ë¦¬ë¡œ\n",
    "  - ë” ì •êµí•œ íŠ¸ë¦¬ë¥¼ ë§Œë“¤ì–´ì„œ\n",
    "  - **ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œë„ í›Œë¥­í•œ ì„±ëŠ¥**ì„ ë³´ì—¬ì¤Œ\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’ ê¸°ì¤€)\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | ì„¤ëª… |\n",
    "|----------|------|\n",
    "| `num_leaves=31` | íŠ¸ë¦¬ì—ì„œ ì‚¬ìš©í•  ë¦¬í”„ ë…¸ë“œ ìˆ˜. ë§ì„ìˆ˜ë¡ ë³µì¡í•œ ëª¨ë¸ ê°€ëŠ¥ |\n",
    "| `max_depth=-1` | íŠ¸ë¦¬ ê¹Šì´ ì œí•œ ì—†ìŒ. ëŒ€ì‹  num_leavesë¡œ ì œì–´ |\n",
    "| `learning_rate=0.1` | í•™ìŠµ ì†ë„. ì‘ì„ìˆ˜ë¡ ì²œì²œíˆ, ê³¼ì í•© ë°©ì§€ |\n",
    "| `n_estimators=100` | íŠ¸ë¦¬ ê°œìˆ˜. ë§ì„ìˆ˜ë¡ ì •êµí•˜ì§€ë§Œ ëŠë ¤ì§ |\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… ì¥ì  ìš”ì•½\n",
    "\n",
    "- **ì†ë„ ë¹ ë¦„**: íŠ¹íˆ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ì••ë„ì \n",
    "- **ë©”ëª¨ë¦¬ íš¨ìœ¨ ì¢‹ìŒ**\n",
    "- **í¬ì†Œ/ê³ ì°¨ì› ë°ì´í„°ì— ê°•í•¨**\n",
    "- **ì„±ëŠ¥ ìš°ìˆ˜**: íŠ¹íˆ í‘œí˜•(tabular) ë°ì´í„°ì—ì„œ ê°•ë ¥\n",
    "\n",
    "## âŒ ë‹¨ì  ìš”ì•½\n",
    "\n",
    "- **leaf-wise ë°©ì‹ì€ ê³¼ì í•© ìœ„í—˜ ìˆìŒ** â†’ ì ì ˆí•œ íŠœë‹ í•„ìš”\n",
    "- **íŒŒë¼ë¯¸í„° ë§ìŒ** â†’ ì´ˆë³´ìì—ê² ì§„ì…ì¥ë²½\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ í•œ ì¤„ ìš”ì•½\n",
    "\n",
    "> LightGBMì€ â€œë¹ ë¥´ê³  ë˜‘ë˜‘í•œ GBDTâ€ë¡œ, ëŒ€ê·œëª¨ ë°ì´í„°ì™€ ë³µì¡í•œ ë¬¸ì œë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ ì‹¤ë¬´ ìµœê°•ìì•¼!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5021e42-184f-4c3d-b325-edb40eaf175b",
   "metadata": {},
   "source": [
    "| ëª¨ë¸         | ì›ë¦¬             | ì¥ì                  | ë‹¨ì                 | ì˜ ì“°ì´ëŠ” ê³³               |\n",
    "| ---------- | -------------- | ------------------ | ----------------- | --------------------- |\n",
    "| **LogReg** | ì„ í˜• + ì‹œê·¸ëª¨ì´ë“œ     | í•´ì„ë ¥, ë¹ ë¦„, í™•ë¥  ì˜ ë³´ì •   | ë¹„ì„ í˜• ëª» ì¡ìŒ          | í…ìŠ¤íŠ¸, í•´ì„ í•„ìš”í•œ ì˜ë£Œ/ì‚¬íšŒ ë°ì´í„° |\n",
    "| **SVM**    | ë§ˆì§„ ìµœëŒ€í™” + ì»¤ë„    | ë³µì¡í•œ ê²½ê³„ ê°€ëŠ¥, ì†Œê·œëª¨ì— ê°•í•¨ | ëŒ€ê·œëª¨ ëŠë¦¼, í™•ë¥  ë³´ì • í•„ìš”  | ì¤‘/ì†Œê·œëª¨ ë¹„ì„ í˜• ë¶„ë¥˜          |\n",
    "| **RF**     | ë°°ê¹…+ëœë¤íŠ¸ë¦¬        | ë²”ìš© ê°•í•¨, ì „ì²˜ë¦¬ ììœ ë¡œì›€    | í•´ì„ ì–´ë ¤ì›€, í¬ì†Œê³ ì°¨ì› ë¹„íš¨ìœ¨ | í‘œí˜• ë°ì´í„°, ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„     |\n",
    "| **GBDT**   | ë¶€ìŠ¤íŒ…            | ë¹„ì„ í˜• ì˜ í•™ìŠµ, í‘œí˜• ê°•í•¨    | ëŠë¦¼, íŠœë‹í•„ìš”          | Kaggle baseline       |\n",
    "| **XGB**    | GBDT+ì •ê·œí™”+2ì°¨ìµœì í™” | ì„±ëŠ¥â†‘, ì„¸ë°€íŠœë‹          | ë©”ëª¨ë¦¬â†‘, ë³µì¡          | Kaggle SOTA           |\n",
    "| **LGBM**   | ë¦¬í”„ ê¸°ë°˜ GBDT     | ì†ë„â†‘, ë©”ëª¨ë¦¬ íš¨ìœ¨â†‘       | ì†Œê·œëª¨ ë¶ˆì•ˆì •           | ëŒ€ê·œëª¨ ë°ì´í„°, Kaggle SOTA  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2771a18-04c9-4ced-aa74-5214e1a0e2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\nakyo\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nakyo\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\nakyo\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a4b3955-9c17-4653-b219-9d445b3c42a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\nakyo\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\nakyo\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\nakyo\\anaconda3\\lib\\site-packages (from lightgbm) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cccbbf25-073c-4903-ae69-fb83da8c91b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: ['id', 'age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
      "cat: ['job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'marital_married', 'marital_single', 'education_secondary', 'education_tertiary', 'education_unknown', 'default_yes', 'housing_yes', 'loan_yes', 'contact_telephone', 'contact_unknown', 'month_aug', 'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep', 'poutcome_other', 'poutcome_success', 'poutcome_unknown']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# 0) 'unknown'ì„ ê²°ì¸¡ì¹˜ ì·¨ê¸‰\n",
    "X_train = X_train.replace(\"unknown\", np.nan)\n",
    "X_val   = X_val.replace(\"unknown\", np.nan)\n",
    "\n",
    "# 0.5) bool/boolean ì»¬ëŸ¼ì„ object(ë¬¸ìì—´)ë¡œ ë°”ê¾¸ê±°ë‚˜, 0/1 ìˆ«ìë¡œ ë°”ê¾¼ë‹¤ (ë‘˜ ì¤‘ í•˜ë‚˜ íƒ1)\n",
    "\n",
    "# [ì˜µì…˜ A] ì¹´í…Œê³ ë¦¬ë¡œ ì²˜ë¦¬í•˜ê³  ì‹¶ë‹¤ â†’ objectë¡œ ìºìŠ¤íŒ…\n",
    "bool_cols = X_train.select_dtypes(include=[\"bool\", \"boolean\"]).columns.tolist()\n",
    "if bool_cols:\n",
    "    X_train[bool_cols] = X_train[bool_cols].astype(\"object\")\n",
    "    X_val[bool_cols]   = X_val[bool_cols].astype(\"object\")\n",
    "\n",
    "# [ì˜µì…˜ B] ìˆ«ì(0/1)ë¡œ ì²˜ë¦¬í•˜ê³  ì‹¶ë‹¤ â†’ int8ë¡œ ìºìŠ¤íŒ… (ìœ„ A ëŒ€ì‹  ì´ê±¸ ì“°ë ¤ë©´ AëŠ” ì£¼ì„ ì²˜ë¦¬)\n",
    "# bool_cols = X_train.select_dtypes(include=[\"bool\", \"boolean\"]).columns.tolist()\n",
    "# if bool_cols:\n",
    "#     X_train[bool_cols] = X_train[bool_cols].astype(\"int8\")\n",
    "#     X_val[bool_cols]   = X_val[bool_cols].astype(\"int8\")\n",
    "\n",
    "# 1) ì»¬ëŸ¼ íƒ€ì… ë¶„ë¦¬ (ìºìŠ¤íŒ… í›„ì— ë‹¤ì‹œ ë½‘ê¸° ì¤‘ìš”!)\n",
    "num_cols  = X_train.select_dtypes(include=[\"int64\", \"float64\", \"int32\", \"float32\", \"int16\", \"float16\", \"int8\"]).columns.tolist()\n",
    "cat_cols  = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "print(\"num:\", num_cols)\n",
    "print(\"cat:\", cat_cols)\n",
    "\n",
    "# 2) íŒŒì´í”„ë¼ì¸\n",
    "num_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"sc\",  StandardScaler()),\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"oh\",  OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4258b893-f064-499c-9bdf-57388c020417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ML ëª¨ë¸ ë¹„êµ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ í•™ìŠµ ì§„í–‰ì¤‘:  17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                       | 1/6 [00:25<02:09, 25.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report \n",
    "\n",
    "models = {\n",
    "    \"logreg\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
    "    # ì„ í˜• ëª¨ë¸ z = w*x + bë¥¼ sigmoid Ïƒ(z)ë¡œ ë³€í™˜í•´ì„œ P(y=1|x) í™•ë¥ ì„ ì¶œë ¥ / ë‹¤ì¤‘ ë¶„ë¥˜ëŠ” softmax\n",
    "    # max_iter=2000 â†’ ìˆ˜ë ´í•  ë•Œê¹Œì§€ ê²½ì‚¬í•˜ê°•ë²• ë°˜ë³µ íšŸìˆ˜ ì¶©ë¶„íˆ ëŠ˜ë¦¼.\n",
    "    # class_weight=\"balanced\" â†’ í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ë¶ˆê· í˜•í•  ë•Œ ìë™ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì¡°ì •.\n",
    "    # ì¥ì : ë¹ ë¦„, í•´ì„ë ¥(ê°€ì¤‘ì¹˜ ë°©í–¥/í¬ê¸°) ì¢‹ìŒ, í™•ë¥  ì¶œë ¥ì´ ì•ˆì •ì .\n",
    "    # ë‹¨ì : ì„ í˜• ê²½ê³„ë§Œ í•™ìŠµ â†’ ë¹„ì„ í˜• íŒ¨í„´ì€ ì˜ ëª» ì¡ìŒ. ìŠ¤ì¼€ì¼ë§ í•„ìˆ˜.\n",
    "    \"svm\": SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\"),\n",
    "    # ì›ë¦¬: â€œë§ˆì§„â€ì„ ìµœëŒ€í™”í•˜ëŠ” ê²°ì •ê²½ê³„ë¥¼ ì°¾ìŒ. ë¹„ì„ í˜• íŒ¨í„´ì€ ì»¤ë„(ì—¬ê¸°ì„  RBF)ë¡œ ë³€í™˜í•´ ë¶„ë¦¬.\n",
    "    # = ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ ë¶„ë¥˜í•˜ë©´ì„œë„ í´ë˜ìŠ¤ ê°„ì˜ ì—¬ìœ  ê³µê°„ì„ ìµœëŒ€í•œ í™•ë³´í•˜ëŠ” ê²½ê³„ì„ ì„ ì°¾ëŠ”ë‹¤\n",
    "    # kernel=\"rbf\" â†’ ê°€ìš°ì‹œì•ˆ(RBFRadial Basis Function) ì»¤ë„ë¡œ ë³µì¡í•œ ê³¡ì„ í˜• ê²½ê³„ í‘œí˜„ ê°€ëŠ¥.\n",
    "    # probability=True â†’ Platt scalingì„ ì´ìš©í•´ í™•ë¥  ê°’ê¹Œì§€ ì¶œë ¥ (ì¶”ê°€ ì—°ì‚° ìˆìŒ).\n",
    "    # class_weight=\"balanced\" â†’ ë¶ˆê· í˜• í´ë˜ìŠ¤ ëŒ€ì‘.\n",
    "    # ì¥ì : ì¤‘/ì†Œê·œëª¨ ë°ì´í„°ì—ì„œ ë¹„ì„ í˜• ë¶„ë¥˜ ì˜í•¨. ë§ˆì§„ ê·¹ëŒ€í™”ë¼ ì¼ë°˜í™” ì„±ëŠ¥ì´ ì¢‹ìŒ.\n",
    "    # ë‹¨ì : ë°ì´í„° í¬ë©´ í•™ìŠµ/ì˜ˆì¸¡ ëŠë ¤ì§. íŒŒë¼ë¯¸í„°(C, gamma) íŠœë‹ í•„ìˆ˜.\n",
    "    \"rf\": RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1),\n",
    "    # ì›ë¦¬: ë°°ê¹…(Bagging) ê¸°ë°˜ ì•™ìƒë¸”. ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œ + ëœë¤ í”¼ì²˜ ì„ íƒìœ¼ë¡œ ì—¬ëŸ¬ íŠ¸ë¦¬ í•™ìŠµ â†’ íˆ¬í‘œ.\n",
    "    # n_estimators=400 â†’ íŠ¸ë¦¬ 400ê°œ. ë§ì„ìˆ˜ë¡ ì•ˆì •ì„±â†‘, ì‹œê°„/ë©”ëª¨ë¦¬ ë¹„ìš©ë„ â†‘.\n",
    "    # n_jobs=-1 â†’ ë©€í‹°ì½”ì–´ ë³‘ë ¬ ì²˜ë¦¬.\n",
    "    # ì¥ì : ì „ì²˜ë¦¬ ê±°ì˜ í•„ìš” ì—†ìŒ, ë²”ìš©ì„± ë†’ìŒ, ê³¼ì í•©ì— ê°•í•¨.\n",
    "    # ë‹¨ì : í•´ì„ë ¥ ë‚®ìŒ, ë§¤ìš° í¬ì†Œ/ê³ ì°¨ì› ë°ì´í„°ì—” ë¹„íš¨ìœ¨.\n",
    "    \"gbdt\": GradientBoostingClassifier(random_state=42),\n",
    "    # ì›ë¦¬: ë¶€ìŠ¤íŒ…(Boosting). ì´ì „ íŠ¸ë¦¬ì˜ ì˜¤ì°¨(ì”ì°¨)ë¥¼ ì ì  ì¤„ì—¬ê°€ë©° ì•½í•œ íŠ¸ë¦¬ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ìŒ“ìŒ.\n",
    "    # í•˜ì´í¼íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’):\n",
    "    # learning_rate=0.1 (ì‘ì„ìˆ˜ë¡ ì²œì²œíˆ, ê³¼ì í•© ë°©ì§€)\n",
    "    # n_estimators=100 (íŠ¸ë¦¬ ê°œìˆ˜, ë§ì„ìˆ˜ë¡ ì •êµ)\n",
    "    # max_depth=3 (ì–•ì€ íŠ¸ë¦¬ë¡œ ë‹¨ê³„ì  ë³´ì •)\n",
    "    # ì¥ì : ë³µì¡í•œ ë¹„ì„ í˜• íŒ¨í„´ì„ ì˜ ì¡ìŒ. í‘œí˜•(tabular)ì—ì„œ ë§¤ìš° ê°•ë ¥.\n",
    "    # ë‹¨ì : íŒŒë¼ë¯¸í„° ë§ìŒ, í•™ìŠµ ëŠë¦¼, ê³¼ì í•© ì£¼ì˜ â†’ ë³´í†µ XGBoost/LightGBMìœ¼ë¡œ ëŒ€ì²´.\n",
    "    \"xgb\": XGBClassifier(\n",
    "        n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.9, colsample_bytree=0.9, eval_metric=\"logloss\", \n",
    "        tree_method=\"gpu_hist\",\n",
    "        predictor=\"gpu_predictor\"\n",
    "    ),\n",
    "    # ì›ë¦¬: GBDT ë°œì „í˜•. 2ì°¨ ë„í•¨ìˆ˜ê¹Œì§€ ì‚¬ìš©í•œ ì •êµí•œ ìµœì í™” + ì •ê·œí™”ë¡œ ê³¼ì í•© ë°©ì§€.\n",
    "    # ì£¼ìš” íŒŒë¼ë¯¸í„°:\n",
    "    # n_estimators=600 â†’ íŠ¸ë¦¬ ìˆ˜.\n",
    "    # max_depth=6 â†’ ê°œë³„ íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´. ê¹Šì„ìˆ˜ë¡ ë³µì¡ íŒ¨í„´, ê³¼ì í•© ìœ„í—˜â†‘.\n",
    "    # learning_rate=0.05 â†’ ì‘ì€ í•™ìŠµë¥ ë¡œ ì²œì²œíˆ í•™ìŠµ (íŠ¸ë¦¬ ê°œìˆ˜ëŠ” ëŠ˜ë ¤ì•¼ í•¨).\n",
    "    # subsample=0.9 â†’ ìƒ˜í”Œ ì¼ë¶€ë§Œ ì‚¬ìš©í•´ ê³¼ì í•© ë°©ì§€.\n",
    "    # colsample_bytree=0.9 â†’ í”¼ì²˜ ì¼ë¶€ë§Œ ì‚¬ìš©í•´ íŠ¸ë¦¬ í•™ìŠµ.\n",
    "    # tree_method=\"hist\" â†’ íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ë¹ ë¥¸ ë¶„í•  (GPU ì“°ë ¤ë©´ \"gpu_hist\").\n",
    "    # ì¥ì : ì†ë„/ì„±ëŠ¥ ê· í˜• ìµœê³ , íŒŒë¼ë¯¸í„° ì„¸ë°€ ì¡°ì • ê°€ëŠ¥.\n",
    "    # ë‹¨ì : íŠœë‹ í•„ìš”, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ â†‘.\n",
    "    \"lgbm\": LGBMClassifier(\n",
    "        n_estimators=1000, learning_rate=0.05,\n",
    "        subsample=0.9, colsample_bytree=0.9, objective=\"binary\",\n",
    "        device=\"gpu\"\n",
    "    )\n",
    "    # (LightGBM)\n",
    "    # ì›ë¦¬: ë˜ ë‹¤ë¥¸ GBDT êµ¬í˜„. ë¦¬í”„ ì¤‘ì‹¬(Tree leaf-wise) ì„±ì¥ + íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ë¶„í• ë¡œ ì†ë„ì™€ ë©”ëª¨ë¦¬ íš¨ìœ¨ ë›°ì–´ë‚¨.\n",
    "    # ì£¼ìš” íŒŒë¼ë¯¸í„°:\n",
    "    # n_estimators=1000 â†’ íŠ¸ë¦¬ ê°œìˆ˜.\n",
    "    # learning_rate=0.05 â†’ ë‚®ì€ í•™ìŠµë¥ , ê³¼ì í•© ë°©ì§€.\n",
    "    # subsample=0.9, colsample_bytree=0.9 â†’ ë°ì´í„°/íŠ¹ì§• ì„œë¸Œìƒ˜í”Œë§.\n",
    "    # objective=\"binary\" â†’ ì´ì§„ ë¶„ë¥˜.\n",
    "    # ì¥ì : ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ì . ì¹´í…Œê³ ë¦¬í˜• ì§ì ‘ ì²˜ë¦¬ ê°€ëŠ¥(categorical_feature).\n",
    "    # ë‹¨ì : ì‘ì€ ë°ì´í„°ì—ì„œ ì˜¤íˆë ¤ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒ. ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì˜ëª» ì“°ë©´ ì„±ëŠ¥ ì €í•˜.\n",
    "}\n",
    "\n",
    "print(\"\\n=== ML ëª¨ë¸ ë¹„êµ ===\")\n",
    "ml_results = []\n",
    "for name, est in tqdm(models.items(), desc=\"ëª¨ë¸ í•™ìŠµ ì§„í–‰ì¤‘\", total=len(models)):\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"est\", est)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    try: \n",
    "        y_prob = pipe.predict_proba(X_val)[:, 1]\n",
    "    except Exception:\n",
    "        y_prob = None\n",
    "    \n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1m = f1_score(y_val, y_pred, average=\"macro\")\n",
    "    auc = (roc_auc_score(y_val, y_prob) if y_prob is not None else np.nan)\n",
    "    ml_results.append((name, acc, f1m, auc))\n",
    "    print(f\"{name:>6s}\")\n",
    "    # >: ì˜¤ë¥¸ìª½ ì •ë ¬, 6: ì´ ë„ˆë¹„ 6ì¹¸, s: - ë¬¸ìì—´(string) íƒ€ì… (ì°¸ê³ : ^6sì´ë©´ ê°€ìš´ë° ì •ë ¬ì„)\n",
    "\n",
    "best_name, *_ = sorted(ml_results, key=lambda t: (np.nan_to_num(t[3]), t[2]), reverse=True)[0]\n",
    "# t[3]: AUC ì ìˆ˜, t[2]: F1 macro ì ìˆ˜ \n",
    "# - AUCê°€ np.nanì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆê¹Œ, ê·¸ê±¸ 0.0ìœ¼ë¡œ ë°”ê¿”ì„œ ë¹„êµ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ì–´ì¤Œ.\n",
    "# - ì¦‰, AUCê°€ ì—†ëŠ” ëª¨ë¸ì€ ì„±ëŠ¥ì´ ë‚®ë‹¤ê³  ê°„ì£¼í•¨.\n",
    "# - AUCë¥¼ ìš°ì„  ê¸°ì¤€ìœ¼ë¡œ, F1 macroë¥¼ ë³´ì¡° ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•¨.\n",
    "# [0]: - ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ í•˜ë‚˜ë§Œ ì„ íƒ\n",
    "# - ë‚˜ë¨¸ì§€ ê°’ë“¤(acc, f1m, auc)ì€ _ë¡œ ë¬´ì‹œ\n",
    "print(f\"\\nBest ML model (AUC/F1 ê¸°ì¤€): {best_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf4d5e39-b4c3-49ae-9e47-9a483bf5a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def is_binary(y):\n",
    "    u = np.unique(y)\n",
    "    return len(u) == 2 and set(u) <= {0, 1}\n",
    "\n",
    "def get_scores_for_auc(pipe, X):\n",
    "    # predict_proba ìˆìœ¼ë©´ 1í´ë˜ìŠ¤ í™•ë¥ , ì—†ìœ¼ë©´ decision_function ì‚¬ìš©\n",
    "    if hasattr(pipe, \"predict_proba\"):\n",
    "        p = pipe.predict_proba(X)\n",
    "        if p.ndim == 2 and p.shape[1] >= 2:\n",
    "            return p[:, 1]\n",
    "    if hasattr(pipe, \"decision_function\"):\n",
    "        return pipe.decision_function(X)\n",
    "    return None\n",
    "\n",
    "def evaluate_model(estimator, name):\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"est\", estimator)])\n",
    "    t0 = time.time()\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fit_sec = time.time() - t0\n",
    "\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1m = f1_score(y_val, y_pred, average=\"macro\")\n",
    "\n",
    "    scores = get_scores_for_auc(pipe, X_val)\n",
    "    auc = roc_auc_score(y_val, scores) if (scores is not None and is_binary(y_val)) else np.nan\n",
    "\n",
    "    print(f\"[{name}] acc={acc:.4f} | f1m={f1m:.4f} | auc={auc if not np.isnan(auc) else float('nan'):.4f} | time={fit_sec:.1f}s\")\n",
    "    return {\"name\": name, \"acc\": acc, \"f1m\": f1m, \"auc\": auc, \"time\": fit_sec}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e15312-0c3d-42d8-b7b0-b545583ebeb9",
   "metadata": {},
   "source": [
    "# PyTorch MLP ì—°ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4831d3-d390-4623-ac6b-8e6126170e73",
   "metadata": {},
   "source": [
    "# ğŸ§© í¬ì†Œ í–‰ë ¬(Sparse Matrix) vs ë°€ì§‘ ë°°ì—´ (Dense Array)\n",
    "Sparse Matrix: ëŒ€ë¶€ë¶„ì˜ ê°’ì´ 0ì¸ í–‰ë ¬. ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ 0ì´ ì•„ë‹Œ ê°’ë§Œ ì €ì¥í•¨.\\\n",
    "Dense Array: ëª¨ë“  ê°’ì„ ë‹¤ ì €ì¥í•˜ëŠ” ì¼ë°˜ì ì¸ ë°°ì—´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd85425-6a7e-43cf-8019-62ad2ba8717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline as Skpipe\n",
    "pre_only = Skpipe([(\"pre\", pre)])\n",
    "Xtr_t = pre_only.fit_transform(X_train)\n",
    "# ë°ì´í„°ë¥¼ ë³´ê³  í•™ìŠµ(fit) + ë³€í™˜(transform)ì„ ë™ì‹œì— ìˆ˜í–‰\n",
    "Xva_t = pre_only.transform(X_val)\n",
    "# ì´ë¯¸ í•™ìŠµëœ ì „ì²˜ë¦¬ê¸°ë¥¼ ì‚¬ìš©í•´ì„œ ë³€í™˜ë§Œ ìˆ˜í–‰\n",
    "\n",
    "# í¬ì†Œ í–‰ë ¬(sparse matrix) -> ë°€ì§‘ ë°°ì—´(dense array)ë¡œ ë³€í™˜ \n",
    "try:\n",
    "    import scipy.sparse as sp\n",
    "    if sp.issparse(Xtr_t): Xtr_t = Xtr_t.toarray()\n",
    "    if sp.issparse(Xva_t): Xva_t = Xva_t.toarray()\n",
    "except Exception:\n",
    "    Xtr_t = np.asarray(Xtr_t); Xva_t = np.asarray(Xva_t)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# TensorDataset: ì—¬ëŸ¬ ê°œì˜ tensorë“¤ì„ í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ ê°ì²´ë¡œ ë¬¶ì–´ì¤Œ _ - ì˜ˆ: ì…ë ¥ ë°ì´í„°ì™€ ì •ë‹µ(label)ì„ í•œ ìŒìœ¼ë¡œ ë§Œë“¤ì–´ì„œ ëª¨ë¸ì´ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•¨.\n",
    "# DataLoader: TensorDatasetê°™ì€ ë°ì´í„°ì…‹ì„ batch ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ ëª¨ë¸ì— ê³µê¸‰í•´ì£¼ëŠ” ì—­í•  \n",
    "# -> í•™ìŠµ ì‹œ ë¯¸ë‹ˆë°°ì¹˜ í•™ìŠµ, ì…”í”Œ, ë³‘ë ¬ ì²˜ë¦¬ ë“±ì„ ì‰½ê²Œ í•  ìˆ˜ ìˆìŒ \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "Xtr_tensor = torch.tensor(Xtr_t, dtype=torch.float32)\n",
    "Xva_tensor = torch.tensor(Xva_t, dtype=torch.float32)\n",
    "ytr_tensor = torch.tensor(np.array(y_train), dtype=torch.long)\n",
    "yva_tensor = torch.tensor(np.array(y_val), dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(Xtr_tensor, ytr_tensor), batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(Xva_tensor, yva_tensor), batch_size=512, shuffle=False)\n",
    "\n",
    "in_dim = Xtr_t.shape[1]\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_dim, 256), nn.ReLU(), nn.Dropout(0.15),\n",
    "    nn.Linear(256, 128), nn.ReLU(), nn.Dropout(0.15),\n",
    "    nn.Linear(128, 1)\n",
    ").to(device)\n",
    "\n",
    "# ë¶ˆê· í˜• ëŒ€ì‘: pos_weight = neg/pos\n",
    "pos = (y_train==1).sum()\n",
    "neg = (y_train==0).sum()\n",
    "pos_weight = torch.tensor([neg / max(pos, 1)], dtype=torch.float, device=device)\n",
    "# í˜¹ì‹œë‚˜ posê°€ 0ì¼ ê²½ìš° ë‚˜ëˆ—ì…ˆ ì˜¤ë¥˜ ë°©ì§€ \n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "# Binary Cross Entropy Loss + Sigmoidë¥¼ í•©ì¹œ ì†ì‹¤ í•¨ìˆ˜ _ ì´ì§„ ë¶„ë¥˜ì—ì„œ ìì£¼ ì‚¬ìš©ë¨ \n",
    "# sigmoidë¥¼ ë¨¼ì € ì ìš©í•œ ë’¤ binary cross entropy ê³„ì‚° \n",
    "# pos weight -> for ë¶ˆê· í˜• í•´ê²° \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "# AdamWëŠ” Adam optimizerì˜ ë³€í˜•ì´ê³ , Weight Decayë¥¼ ë” ì œëŒ€ë¡œ ì²˜ë¦¬í•´ì£¼ëŠ” ë²„ì „ \n",
    "# ì¼ë°˜ Adamì€ L2 ì •ê·œí™”ë¥¼ ì˜ëª» ì ìš©í•˜ëŠ” ë¬¸ì œê°€ ìˆì—ˆëŠ”ë° AdamWëŠ” ê·¸ê±¸ ê³ ì¹¨ \n",
    "# model.parameters(): ëª¨ë¸ì˜ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë“¤ì„ ê°€ì ¸ì˜´ (ê°€ì¤‘ì¹˜, í¸í–¥ ë“±)\n",
    "# lr=1e-3: í•™ìŠµë¥ ì„ 0.001ë¡œ ì„¤ì •. ì´ ê°’ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ ì—…ë°ì´íŠ¸í• ì§€ë¥¼ ê²°ì •\n",
    "# AdamW: parameter update ë°©ì‹ìœ¼ë¡œ ì‚¬ìš© _ ë‚´ë¶€ì ìœ¼ë¡œëŠ” momentum, adaptice learning rate, weight decayë¥¼ ì˜ ì¡°í•©í•¨ \n",
    "# Adam: (íŠ¹ì§•) ë¹ ë¥¸ ìˆ˜ë ´, ì ì‘ì  í•™ìŠµë¥  (ì¥ì ) ì¼ë°˜ì ì¸ ìƒí™©ì—ì„œ ì˜ ì‘ë™\n",
    "# AdamW: (íŠ¹ì§•) Weight Decay ë¶„ë¦¬ ì ìš©, (ì¥ì ) ì •ê·œí™”ê°€ í•„ìš”í•œ ëª¨ë¸ì— ë” ì•ˆì •ì  \n",
    "\n",
    "best_auc = -1.0\n",
    "best_state = None\n",
    "for epoch in range(1,21): \n",
    "    model.train()\n",
    "    # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì • \n",
    "    epoch_loss = 0.0\n",
    "    # í•œ epoch ë™ì•ˆì˜ ì´ ì†ì‹¤ì„ ì €ì¥í•  ë³€ìˆ˜ \n",
    "    for xb, yb in train_loader:\n",
    "        # train_loaderëŠ” DataLoaderë¡œë¶€í„° batch ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´ \n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        # xb: ì…ë ¥ ë°ì´í„°, yb: ì •ë‹µ ë¼ë²¨ \n",
    "        optimizer.zero_grad()\n",
    "        # ì´ì „ ë°°ì¹˜ì—ì„œ ê³„ì‚°ëœ graedient ì´ˆê¸°í™” \n",
    "        logits = model(xb).squeeze(1)\n",
    "        # ëª¨ë¸ì— ì…ë ¥ì„ ë„£ê³  ì˜ˆì¸¡ê°’(logits)ì„ ì–»ìŒ\n",
    "        # squeeze(1)ì€ [batch_size, 1] -> [batch_size]ë¡œ ì°¨ì› ì¶•ì†Œ\n",
    "        loss = criterion(logits, yb.float())\n",
    "        # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì„ ë¹„êµí•´ì„œ ì†ì‹¤ ê³„ì‚° \n",
    "        loss.backward()\n",
    "        # ì†ì‹¤ì„ ê¸°ì¤€ìœ¼ë¡œ gradient ê³„ì‚° (ì—­ì „íŒŒ)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # gradient í­ì£¼ ë°©ì§€ìš©. gradientì˜ normì„ ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ \n",
    "        optimizer.step()\n",
    "        # ê³„ì‚°ëœ gradient ê¸°ë°˜ìœ¼ë¡œ parameter update \n",
    "        epoch_loss += loss.item() * xb.size(0)\n",
    "        # loss.item: í˜„ì¬ ë°°ì¹˜ì˜ í‰ê·  ì†ì‹¤ \n",
    "        # ë°°ì¹˜ í‰ê·  ì†ì‹¤ Ã— ë°°ì¹˜ í¬ê¸° = ë°°ì¹˜ ì „ì²´ ì†ì‹¤ í•©\n",
    "        # í˜„ì¬ ë°°ì¹˜ì˜ ì†ì‹¤ ê°’ì„ floatë¡œ ê°€ì ¸ì˜´\n",
    "        # ì´ê±¸ epoch_lossì— ê³„ì† ë”í•´ì„œ â†’ í•œ epoch ì „ì²´ ì†ì‹¤ í•©ì„ êµ¬í•˜ëŠ” ê±°ì•¼\n",
    "    epoch_loss /= len(train_loader.dataset)\n",
    "    # ì „ì²´ ì†ì‹¤ì„ ìƒ˜í”Œ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ëˆ„ì í•´ì„œ í‰ê·  ì†ì‹¤ ê³„ì‚° \n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    probs, ys = [], []\n",
    "    with torch.no_grad():\n",
    "        # gradient ê²Œì‚°ì„ ë” -> ë©”ëª¨ë¦¬ ì ˆì•½ + ì†ë„ í–¥ìƒ \n",
    "        # validationì€ í•™ìŠµì´ ì•„ë‹ˆë‹ˆê¹Œ gradient í•„ìš” ì—†ìŒ \n",
    "        for xb, yb in val_loader: # validation ë°ì´í„°ë¥¼ batch ë‹¨ìœ„ë¡œ ë¶ˆëŸ¬ì˜´ \n",
    "            xb = xb.to(deivice)\n",
    "            p = torch.sigmoid(model(xb).squeeze(1)).cpu().numpy()\n",
    "            # ëª¨ë¸ì— ì…ë ¥ ë„£ê³  logits ì¶œë ¥, ì¶œë ¥ì´ [batch_size, 1]ì¼ ê²½ìš° â†’ squeeze(1)ë¡œ [batch_size]ë¡œ ë°”ê¿”ì¤Œ\n",
    "            # logitsë¥¼ í™•ë¥ ë¡œ ë³€í™˜ \n",
    "            # sigmoiëŠ” 0~1 ì‚¬ì´ì˜ ê°‘ìŠ¹ë¡œ ë°”ê¿”ì£¼ë‹ˆê¹Œ ì´ê²Œ ì–‘ì„± í´ë˜ìŠ¤ì¼ í™•ë¥ ë¡œ ë‚˜ì˜´\n",
    "            probs.append(p); ys.append(yb.numpy())\n",
    "            # pëŠ” numpy ë°°ì—´ë¡œ ë³€í™˜ëœ í™•ë¥ ê°’ \n",
    "            # ì´ê±¸ ë¦¬ìŠ¤íŠ¸ì— ê³„ì† ëˆ„ì í•´ì„œ ì „ì²´ validation ê²°ê³¼ ì €ì¥  \n",
    "        probs = np.concatenate(probs); ys = np.concatenate(ys)\n",
    "        preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "        f1m = f1_score(ys, preds, average=\"macro\")\n",
    "        try: \n",
    "            auc = roc_auc_score(ys, probs)\n",
    "        except ValueError: \n",
    "            auc = np.nan\n",
    "\n",
    "        if (auc if not np.isnan(auc) else -1) > best_auc: \n",
    "            # AUCê°€ ì´ì „ë³´ë‹¤ ë” ì¢‹ìœ¼ë©´ ëª¨ë¸ ìƒíƒœ ì €ì¥ \n",
    "            best_auc = auc \n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            # ëª¨ë¸ì˜ ëª¨ë“  íŒŒë¼ë¯¸í„°(ê°€ì¤‘ì¹˜, í¸í–¥ ë“±)ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜ \n",
    "            # GPUì— ìˆë˜ tensorë¥¼ CPUë¡œ ì˜®ê¸°ê³  ë³µì‚¬í•¨ _ ì™œ ë³µì‚¬í•˜ëƒë©´ ì´í›„ í•™ìŠµì´ ê³„ì†ë˜ë©´ ëª¨ë¸ íŒŒë¼ë¯¸í„°ê°€ ë°”ë€Œë‹ˆê¹Œ, ê·¸ ìˆœê°„ì˜ ìƒíƒœë¥¼ ì•ˆì „í•˜ê²Œ ì €ì¥í•˜ë ¤ê³   \n",
    "        \n",
    "        print(f\"[EP {epoch:02d}] train_loss={epoch_loss:.4f} val_f1={f1m:.4f} val_auc={auc:.4f}\")\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "print(f\"Best DL AUC: {best_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eeb0f3-7f80-4e24-84f3-1170b4ee7fda",
   "metadata": {},
   "source": [
    "# ë°ì´í„° í˜•íƒœ ì •í™•í•˜ê²Œ ë§ì¶°ì£¼ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92dcad8-be4f-480f-b667-7f147cf0b173",
   "metadata": {},
   "source": [
    "PyTorchì—ì„œëŠ” tensorì™€ numpy array ì‚¬ì´ì˜ ë³€í™˜ì´ ìì£¼ ì¼ì–´ë‚¨ _ ì •ë¦¬ í•„ìš” \n",
    "\n",
    "### ğŸ” tensor vs numpy array ì°¨ì´ì \n",
    "| í•­ëª©            | torch.Tensor                  | numpy.ndarray                  |\n",
    "|-----------------|-------------------------------|--------------------------------|\n",
    "| ì‚¬ìš© ëª©ì        | PyTorch ëª¨ë¸ í•™ìŠµ, ì—°ì‚°       | ì¼ë°˜ì ì¸ ìˆ˜ì¹˜ ê³„ì‚°, í‰ê°€        |\n",
    "| GPU ì‚¬ìš© ê°€ëŠ¥   | âœ… ê°€ëŠ¥ (`.to(device)`)       | âŒ ë¶ˆê°€ëŠ¥                       |\n",
    "| ìë™ ë¯¸ë¶„       | âœ… ê°€ëŠ¥ (`.backward()`)       | âŒ ë¶ˆê°€ëŠ¥                       |\n",
    "| ëª¨ë¸ ì…ë ¥       | âœ… ì‚¬ìš©ë¨                     | âŒ ì§ì ‘ ì…ë ¥ ë¶ˆê°€               |\n",
    "| í‰ê°€ ì§€í‘œ ê³„ì‚°  | âŒ ë¶ˆí¸í•¨                     | âœ… `sklearn` ë“±ì—ì„œ ì‚¬ìš© ìš©ì´   |\n",
    "\n",
    "\n",
    "### ğŸ“¥ ëª¨ë¸ì— ë“¤ì–´ê°ˆ ë•Œ: torch.Tensor\n",
    "- ëª¨ë¸ì— ì…ë ¥í•  ë•ŒëŠ” ë¬´ì¡°ê±´ tensor í˜•íƒœì—¬ì•¼ í•´\n",
    "- ì˜ˆ: model(xb)ì—ì„œ xbëŠ” tensorì—¬ì•¼ í•¨\n",
    "- GPUì—ì„œ í•™ìŠµí•˜ë ¤ë©´ .to(device)ë„ ê¼­ í•´ì¤˜ì•¼ í•¨\\\n",
    ">xb = xb.to(device)  # tensor í˜•íƒœë¡œ GPUì— ì˜¬ë¦¼\\\n",
    "logits = model(xb)  # ëª¨ë¸ì— ì…ë ¥\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ“¤ ëª¨ë¸ì—ì„œ ë‚˜ì˜¬ ë•Œ: tensor â†’ numpyë¡œ ë³€í™˜\n",
    "- ëª¨ë¸ ì¶œë ¥ì€ tensor í˜•íƒœì•¼\n",
    "- í‰ê°€í•  ë•ŒëŠ” numpyë¡œ ë°”ê¿”ì„œ sklearn ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ë„˜ê²¨ì¤˜ì•¼ í•¨\n",
    ">p = torch.sigmoid(logits).cpu().numpy()  # í™•ë¥ ë¡œ ë°”ê¾¸ê³  numpyë¡œ ë³€í™˜\n",
    "\n",
    "\n",
    "- .cpu()ëŠ” GPUì—ì„œ CPUë¡œ ì˜®ê¸°ëŠ” ì‘ì—…\n",
    "- .numpy()ëŠ” tensor â†’ numpy arrayë¡œ ë³€í™˜\n",
    "\n",
    "### ğŸ¯ ì™œ ë³€í™˜í•˜ëƒë©´...\n",
    "- PyTorchëŠ” í•™ìŠµì— ìµœì í™”ëœ í”„ë ˆì„ì›Œí¬\n",
    "- numpyëŠ” í‰ê°€ ì§€í‘œ ê³„ì‚°, ì‹œê°í™” ë“±ì— ë” ì í•©\n",
    "- ì˜ˆ: roc_auc_score, confusion_matrix, plot() ë“±ì€ numpyë¥¼ ìš”êµ¬í•¨\n",
    "\n",
    "### ğŸ’¡ íë¦„ ìš”ì•½\n",
    "- ë°ì´í„° ë¡œë”©: numpy â†’ tensorë¡œ ë³€í™˜ (TensorDataset)\n",
    "- ëª¨ë¸ í•™ìŠµ: tensor í˜•íƒœë¡œ GPUì— ì˜¬ë ¤ì„œ í•™ìŠµ\n",
    "- ëª¨ë¸ ì¶œë ¥: tensor í˜•íƒœë¡œ ë‚˜ì˜´\n",
    "- í‰ê°€ ë‹¨ê³„: tensor â†’ numpyë¡œ ë³€í™˜í•´ì„œ ì§€í‘œ ê³„ì‚°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2708a89a-64ec-419f-8a9c-c8abd1230075",
   "metadata": {},
   "source": [
    "# ë¨¸ì‹ ëŸ¬ë‹ ë°ì´í„° í˜•íƒœ ì •ì˜ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a4b2e3-b3aa-44c9-ab64-5c4ffc8b2fda",
   "metadata": {},
   "source": [
    "ëŒ€ë¶€ë¶„ì˜ ë¨¸ì‹ ëŸ¬ë‹ library(ex: scikit-learn)ì€ numpy.ndarray ë˜ëŠ” pandas.DataFrame í˜•íƒœì˜ ë°ì´í„° ì‚¬ìš©í•¨ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e396b-4748-4d5b-ad7f-3c712cd18d59",
   "metadata": {},
   "source": [
    "# numpy.ndarray vs torch.Tensor\n",
    "> np_arr = np.array([[1, 2], [3, 4]])       # shape: (2, 2)\\\n",
    "tensor = torch.tensor([[1, 2], [3, 4]])   # shape: (2, 2)\n",
    "\n",
    "> **numpy ì—°ì‚°**\\\n",
    ">np_arr = np.array([[1, 2], [3, 4]])\n",
    ">print(np_arr * 2)  # ë‹¨ìˆœ ê³±ì…ˆ\n",
    "\n",
    "> **tensor ì—°ì‚°**\\\n",
    ">tensor = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32, requires_grad=True)\n",
    "print(tensor * 2)  # ê³±ì…ˆ + gradient ì¶”ì  ê°€ëŠ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee56ad0-1e93-46d8-9430-342fa8199eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
